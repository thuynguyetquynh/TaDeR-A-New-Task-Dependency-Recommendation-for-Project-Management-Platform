{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Get_GloVe_features.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pbSuD_3JgzAk"},"source":["# Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRiQVMhngzAm","executionInfo":{"status":"ok","timestamp":1634440675550,"user_tz":-420,"elapsed":556,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"630a4f3b-035b-44a2-94f0-350eab71706a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"oA6TR9ongzAm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634440684739,"user_tz":-420,"elapsed":8695,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"e44c6122-c6e6-4bae-95ef-215852d5ce06"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import networkx as nx\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import datetime\n","import gc\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk import word_tokenize\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","tf.random.set_seed(123)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_pxWxxCcCJw","executionInfo":{"status":"ok","timestamp":1634440684741,"user_tz":-420,"elapsed":27,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"ccfec74f-2349-40bd-c621-f33b830e6dca"},"source":["cd /content/drive/MyDrive/AISIA/Jira recommendation/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AISIA/Jira recommendation\n"]}]},{"cell_type":"markdown","metadata":{"id":"MTlk8R4WfvUu"},"source":["# Load dataset"]},{"cell_type":"code","metadata":{"id":"WUAyPH7y26Cc","executionInfo":{"status":"ok","timestamp":1634440684742,"user_tz":-420,"elapsed":22,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def encode_graph(row):\n","  new_row = []\n","  for i in row:\n","    if i==0:\n","      new_row.append([1,0])\n","    else:\n","      new_row.append([0,1])\n","  return new_row"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0vt5UFbuSQ1","executionInfo":{"status":"ok","timestamp":1634440684743,"user_tz":-420,"elapsed":22,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def load_project(project_name):\n","  # Attributes\n","  df = pd.read_csv('data/{}/attribute_preprocess.csv'.format(project_name))\n","  df = df.fillna('')\n","  # Graph\n","  graph = pd.read_csv('data/{}/graph.csv'.format(project_name), delimiter=',')\n","  graph = graph.apply(encode_graph)\n","  graph = graph.values\n","  return df, graph"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9k8yA8QMujWw"},"source":["## GloVe"]},{"cell_type":"code","metadata":{"id":"voYo6gqlaSv2","executionInfo":{"status":"ok","timestamp":1634440928724,"user_tz":-420,"elapsed":244003,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def load_word_embeddings(fname):\n","    wordvecs = {}\n","    with open(fname, 'r') as file:\n","        lines = file.readlines()\n","        for line in lines:\n","            tokens = line.split(' ')\n","            vec = np.array(tokens[1:], dtype=np.float32)\n","            wordvecs[tokens[0]] = vec\n","\n","    return wordvecs \n","\n","wordvecs = load_word_embeddings(\"embedding/glove.42B.300d.txt\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_94AEvOMR8I","executionInfo":{"status":"ok","timestamp":1634440928725,"user_tz":-420,"elapsed":23,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["__PADDED_INDEX__ = 0 \n","__UNKNOWN_WORD__ = 1"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMsrV32sPFaa","executionInfo":{"status":"ok","timestamp":1634440928725,"user_tz":-420,"elapsed":21,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"0042f101-3611-4757-d72a-f579cf05df39"},"source":["vocab = wordvecs.keys()\n","matrix = list(wordvecs.values())\n","del wordvecs\n","gc.collect()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"mLc7nY0UYp6D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634440929953,"user_tz":-420,"elapsed":1243,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"dc72a921-bbe2-485c-f3e9-9bec2137a018"},"source":["word_to_index = {word: index+2 for index, word in enumerate(vocab)}\n","del vocab\n","gc.collect()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["52"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"0V2cXjDjS8_O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634440988863,"user_tz":-420,"elapsed":58915,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"94fc7c0b-18a0-4eca-a26b-6401b090fdf6"},"source":["embedding_matrix = np.pad(matrix, [[2,0],[0,0]], mode='constant', constant_values =0.0)\n","del matrix\n","gc.collect()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"qXTofqjTfxIo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634440988865,"user_tz":-420,"elapsed":27,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"1f16db26-1b72-4be5-b16f-4417785ab08f"},"source":["len(word_to_index), len(embedding_matrix)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1917494, 1917496)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"8IhkpwRHob0R"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"Ly-enb4GP03f"},"source":["### Get features"]},{"cell_type":"code","metadata":{"id":"HA78gq_IhZah","executionInfo":{"status":"ok","timestamp":1634440988868,"user_tz":-420,"elapsed":24,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def glove_tokenizer(sentences):\n","  tokenized_texts = [nltk.tokenize.word_tokenize(text) for text in sentences]\n","  X = []\n","  for text in tokenized_texts:\n","    cur_text_indices = []\n","    for word in text:\n","      if word in word_to_index:\n","          cur_text_indices.append(word_to_index[word])    \n","      else:\n","          cur_text_indices.append(__UNKNOWN_WORD__)  \n","    X.append(cur_text_indices)\n","  return X"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"0uKrgeS9HkpU","executionInfo":{"status":"ok","timestamp":1634440988869,"user_tz":-420,"elapsed":24,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def get_textual_features(df):\n","  df[\"title\"] = df[\"title\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","  df[\"description\"] = df[\"description\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","  df[\"summary\"] = df[\"summary\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","\n","  # Extract data from dataframe\n","  titles = df['title'].values\n","  descriptions = df['description'].values\n","  summaries = df['summary'].values\n","\n","  return titles, descriptions, summaries"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9J_JCdZ1hFll","executionInfo":{"status":"ok","timestamp":1634440988870,"user_tz":-420,"elapsed":25,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["def return_model(value_maxlen):\n","  inputs_A = keras.Input(shape=(value_maxlen), name=\"input_a\")\n","\n","  embedding_layer = keras.layers.Embedding(input_dim=embedding_matrix.shape[0],   \n","                 output_dim=embedding_matrix.shape[1],   \n","                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  \n","                  trainable=False,                     \n","                 mask_zero=True)                 \n","\n","  # Embedding\n","  emb_A = embedding_layer(inputs_A)\n","  \n","  model = keras.Model(inputs=[inputs_A], outputs=emb_A)\n","  model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"categorical_accuracy\"])\n","  \n","  model.summary()\n","\n","  return model"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02oiSc4QQwlA"},"source":["### Start"]},{"cell_type":"code","metadata":{"id":"nxT9qdSmQhbi","executionInfo":{"status":"ok","timestamp":1634440988871,"user_tz":-420,"elapsed":25,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["list_project_names = [('FLUME', 1577, 5, 200, 256), ('MDLSITE', 4100, 12, 200, 256)]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kmt0pJTpoaqS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1634441300481,"user_tz":-420,"elapsed":311635,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"0035dfac-3dfb-48d2-f8eb-1d4f55dccbb0"},"source":["for project in list_project_names:\n","  project_name = project[0]\n","  time_split = project[1]\n","\n","  # Model params\n","  steps_per_epoch = project[2]\n","  epochs = project[3]\n","  batch_size = project[4]\n","\n","  # Load dataset\n","  df, graph = load_project(project_name)\n","\n","  # Get features\n","  titles, descriptions, summaries = get_textual_features(df)\n","  del df\n","  del graph\n","  gc.collect()\n","\n","  # Save path\n","  path = 'embedding/fasttext/{}/'.format(project_name)\n","  try:\n","    os.mkdir(path)\n","  except:\n","    print('Cannot create path {}'.format(path))\n","\n","  # All textual features\n","  value_maxlen = 540\n","  all_text = [descriptions[i] +' '+titles[i] + ' '+summaries[i] for i in range(0, len(titles))]\n","  model = return_model(value_maxlen)\n","  \n","  save_path = path\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  tokenized = fasttext_tokenizer(all_text)\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  feature = model.predict(padded)\n","  np.save(save_path + 'textual_features.npy', feature) \n","  del all_text\n","  del tokenized\n","  del model\n","  gc.collect()\n","\n","  value_maxlen = 20\n","  # Only title\n","  model = return_model(value_maxlen)\n","  save_path = path + \"title/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  tokenized = fasttext_tokenizer(titles)\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","\n","  np.save(save_path + 'textual_features.npy', feature) \n","  del model\n","  gc.collect()\n","\n","  # Only summary\n","  model = return_model(value_maxlen)\n","  save_path = path + \"summary/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  tokenized = fasttext_tokenizer(summaries)\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","  \n","  np.save(save_path + 'textual_features.npy', feature) \n","  del model\n","  gc.collect()\n","\n","  value_maxlen = 500\n","  # Only description\n","  model = return_model(value_maxlen)\n","  save_path = path + \"description/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  tokenized = fasttext_tokenizer(descriptions)\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","\n","  np.save(save_path + 'textual_features.npy', feature) \n","  del model\n","  gc.collect()\n","\n","  value_maxlen = 520\n","  # description + title\n","  model = return_model(value_maxlen)\n","  save_path = path + \"description_title/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  all_text = [descriptions[i] +' '+titles[i] for i in range(0, len(titles))]\n","  tokenized = fasttext_tokenizer(all_text)\n","\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","  \n","  np.save(save_path + 'textual_features.npy', feature) \n","  del all_text\n","  del model\n","  gc.collect()\n","\n","  # description + summary\n","  model = return_model(value_maxlen)\n","  save_path = path + \"description_summary/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  all_text = [descriptions[i] +' '+summaries[i] for i in range(0, len(titles))]\n","  tokenized = fasttext_tokenizer(all_text)\n","\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","  \n","  np.save(save_path + 'textual_features.npy', feature) \n","  del all_text\n","  del model\n","  gc.collect()\n","\n","  # title + summary\n","  model = return_model(value_maxlen)\n","  valye_maxlen = 40\n","  save_path = path + \"title_summary/\"\n","  try:\n","    os.mkdir(save_path)\n","  except:\n","    print('Cannot create path {}'.format(save_path))\n","  all_text = [titles[i] +' '+summaries[i] for i in range(0, len(titles))]\n","  tokenized = fasttext_tokenizer(all_text)\n","  padded = pad_sequences(tokenized, maxlen=value_maxlen, padding = 'post', truncating=\"post\")\n","  del tokenized\n","  gc.collect()\n","\n","  feature = model.predict(padded)\n","  del padded\n","  gc.collect()\n","  \n","  np.save(save_path + 'textual_features.npy', feature) \n","  del all_text\n","  del model\n","  gc.collect()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 540)]             0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 540, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Cannot create path embedding/glove/FLUME/\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 20)]              0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 20, 300)           575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 20)]              0         \n","_________________________________________________________________\n","embedding_2 (Embedding)      (None, 20, 300)           575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 500)]             0         \n","_________________________________________________________________\n","embedding_3 (Embedding)      (None, 500, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 520)]             0         \n","_________________________________________________________________\n","embedding_4 (Embedding)      (None, 520, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 520)]             0         \n","_________________________________________________________________\n","embedding_5 (Embedding)      (None, 520, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 520)]             0         \n","_________________________________________________________________\n","embedding_6 (Embedding)      (None, 520, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Model: \"model_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_a (InputLayer)         [(None, 540)]             0         \n","_________________________________________________________________\n","embedding_7 (Embedding)      (None, 540, 300)          575248800 \n","=================================================================\n","Total params: 575,248,800\n","Trainable params: 0\n","Non-trainable params: 575,248,800\n","_________________________________________________________________\n","Cannot create path embedding/glove/MDLSITE/\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-961515ea8647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_maxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'textual_features.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m     \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;31m# If originally PSS strategy was used, then replace it back since predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Discards the path arg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m       path for path, _ in _yield_flat_up_to(shallow_tree, inputs[0], is_seq))\n\u001b[1;32m   1474\u001b[0m   results = [\n\u001b[0;32m-> 1475\u001b[0;31m       \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_path_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_value_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m   ]\n\u001b[1;32m   1477\u001b[0m   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1473\u001b[0m       path for path, _ in _yield_flat_up_to(shallow_tree, inputs[0], is_seq))\n\u001b[1;32m   1474\u001b[0m   results = [\n\u001b[0;32m-> 1475\u001b[0;31m       \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_path_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_value_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m   ]\n\u001b[1;32m   1477\u001b[0m   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_, *values)\u001b[0m\n\u001b[1;32m   1376\u001b[0m   return map_structure_with_tuple_paths_up_to(\n\u001b[1;32m   1377\u001b[0m       \u001b[0mshallow_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Discards the path arg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m       **kwargs)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   2910\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1768\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5910,540,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXzn7o1RUOGg","executionInfo":{"status":"ok","timestamp":1634441688513,"user_tz":-420,"elapsed":375,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"edc56b38-9f71-48a5-f99e-9a31f51f9448"},"source":["padded.shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5910, 540)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QTeyPxYPqkb","executionInfo":{"status":"ok","timestamp":1634441702244,"user_tz":-420,"elapsed":460,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}},"outputId":"d87f6339-5011-44d2-e132-6d9cd9a0f77a"},"source":["a = model.predict(padded[0])\n","b = model.predict(padded[1])"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Model was constructed with shape (None, 540) for input KerasTensor(type_spec=TensorSpec(shape=(None, 540), dtype=tf.float32, name='input_a'), name='input_a', description=\"created by layer 'input_a'\"), but it was called on an input with incompatible shape (None, 1).\n"]}]},{"cell_type":"code","metadata":{"id":"RB1DCdApUbF_"},"source":["1+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3S3itRkfTjhr","executionInfo":{"status":"ok","timestamp":1634441707441,"user_tz":-420,"elapsed":434,"user":{"displayName":"Khoang Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05898184266481346839"}}},"source":["path = \"/content/drive/MyDrive/AISIA/Jira recommendation/embedding/glove/post/FLUME/textual_features.npy\""],"execution_count":26,"outputs":[]}]}