{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3_GloVe_CNN_finetune_post.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_pfkipERUp2S"},"source":["### Library"]},{"cell_type":"code","metadata":{"id":"Gzd9eiVHUp2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630142288348,"user_tz":-420,"elapsed":330,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}},"outputId":"48cd679e-5bfe-4ea7-e2ca-6bbc30928ea2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DT07UTxEUp2T","executionInfo":{"status":"ok","timestamp":1630142294014,"user_tz":-420,"elapsed":5281,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import networkx as nx\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import random\n","import gc\n","import datetime\n","import itertools\n","import re\n","tf.random.set_seed(123)\n","\n","import time"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hlmmdue2LxF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630142294022,"user_tz":-420,"elapsed":34,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}},"outputId":"6b763703-e72e-4332-ab6f-1ecb1a5b286c"},"source":["cd /content/drive/MyDrive/AISIA/Jira recommendation/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/AISIA/Jira recommendation\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MTlk8R4WfvUu"},"source":["# Load dataset"]},{"cell_type":"code","metadata":{"id":"WUAyPH7y26Cc","executionInfo":{"status":"ok","timestamp":1630142294023,"user_tz":-420,"elapsed":30,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def encode_graph(row):\n","  new_row = []\n","  for i in row:\n","    if i==0:\n","      new_row.append([1,0])\n","    else:\n","      new_row.append([0,1])\n","  return new_row"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0vt5UFbuSQ1","executionInfo":{"status":"ok","timestamp":1630142294023,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def load_project(project_name):\n","  # Attributes\n","  df = pd.read_csv('data/{}/attribute_preprocess.csv'.format(project_name))\n","  df = df.fillna('')\n","  # Graph\n","  graph = pd.read_csv('data/{}/graph.csv'.format(project_name), delimiter=',')\n","  graph = graph.apply(encode_graph)\n","  graph = graph.values\n","  return df, graph"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I6JY3Eh71lr5"},"source":["# Get features"]},{"cell_type":"code","metadata":{"id":"b524oFZS1nLg","executionInfo":{"status":"ok","timestamp":1630142294024,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def get_textual_features(df, choose_feature_string):\n","  # Load title/description/summary vectors\n","  loading_path = 'embedding/glove/post/{}/'.format(project_name)\n","  if len(choose_feature_string)!=3:\n","    for feature in choose_feature_string:\n","      print('Loading',feature)\n","      loading_path+=feature+'_'\n","    loading_path = loading_path[:-1]+'/'\n","  all_textual_vectors = np.load(loading_path + 'textual_features.npy')\n","  return all_textual_vectors"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"utF8crt95KQ4","executionInfo":{"status":"ok","timestamp":1630142294024,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def get_time_features(df):\n","  createds = pd.to_datetime(df['created'])\n","  updateds = pd.to_datetime(df['updated'])\n","  return [createds, updateds]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WdaXoWHxvKkw"},"source":["# Split data"]},{"cell_type":"code","metadata":{"id":"UX3KbV9xHScF","executionInfo":{"status":"ok","timestamp":1630142294025,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def split_data(createds, graph, time_split):\n","  # Get date to split data\n","  x = createds[0]\n","  check_date = x + abs(datetime.timedelta(time_split))\n","\n","  train_nodes = []\n","  test_nodes = []\n","\n","  for i in range(0, len(createds)):\n","    if createds[i]<=check_date:\n","      train_nodes.append(i)\n","    else:\n","      test_nodes.append(i) \n","\n","  # Delete all lonely nodes in test\n","  c = 0\n","  new_test_node = []\n","  for i in test_nodes:\n","    t = True\n","    for j in graph[i,:]:\n","      if j[1]!=0: # has linked\n","        t = False\n","    if not t:\n","      c+=1\n","      new_test_node.append(i)\n","\n","  test_nodes = new_test_node\n","  all_nodes = train_nodes + test_nodes\n","\n","  return train_nodes, test_nodes, all_nodes"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ak4kwhPFeO8h"},"source":["### Pairing"]},{"cell_type":"code","metadata":{"id":"AS-10zImeO8h","executionInfo":{"status":"ok","timestamp":1630142294025,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def get_pairs(graph, list_nodes_1, list_nodes_2):\n","  # Get size\n","  size_1 = len(list_nodes_1)\n","  size_2 = len(list_nodes_2)\n","\n","  # Get index of pairs\n","  pairs = np.empty((size_1*size_2,2))\n","  # Get label\n","  labels = np.empty((size_1*size_2,2))\n","\n","  c=0\n","  for i in tqdm(range(0, size_1)):\n","    for j in range(0, size_2):\n","      u = list_nodes_1[i]\n","      v = list_nodes_2[j]\n","      if u!=v:\n","        # Get index of pairs\n","        pairs[c] = [u,v]\n","        # Get label\n","        labels[c] = graph[u][v]\n","        c+=1\n","\n","  pairs = pairs[:c]\n","  labels = labels[:c]\n","  return pairs, labels"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5TNFM5EteO8j"},"source":["# Get training dataset"]},{"cell_type":"code","metadata":{"id":"9IP4YNAqEYMO","executionInfo":{"status":"ok","timestamp":1630142294026,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def create_pair_dataset(pairs, labels):\n","  # Get data\n","  # Index of pairs which have link\n","  link_data_index = np.array([i for i in range(len(pairs)) if labels[i][0]==0])\n","\n","  # Index of pairs which don't have link\n","  non_link_data_index = np.array([i for i in range(len(pairs)) if labels[i][0]==1])\n","\n","  return link_data_index, non_link_data_index\n","\n","def get_separated_data_pairs(input, add_feature = None):\n","  pairs, labels, createds, updateds = input\n","\n","  link_data_index, non_link_data_index = create_pair_dataset(pairs, labels)\n","  \n","  link_data = []\n","  non_link_data = []\n","  print('Get training data pairs')\n","  # Get link_data\n","  for index in tqdm(link_data_index):\n","      p = pairs[index]\n","      u = int(p[0])\n","      v = int(p[1])\n","      link_data.append([u, v])\n","      \n","  # Get non_link_data\n","  for index in tqdm(non_link_data_index):\n","      p = pairs[index]\n","      u = int(p[0])\n","      v = int(p[1])\n","      non_link_data.append([u, v])\n","  \n","  if add_feature != None:\n","    print('Get time features!')\n","    link_other_features = []\n","    non_link_other_features = []\n","    \n","    # Get link_data\n","    for index in tqdm(link_data_index):\n","        p = pairs[index]\n","        u = int(p[0])\n","        v = int(p[1])\n","\n","        cre_u = createds[u]\n","        \n","        if add_feature==1: # Only cre-cre feature\n","          cre_v = createds[v]\n","          cre_cre = abs((cre_u - cre_v).days)\n","          link_other_features.append([cre_cre])\n","        else:\n","          if add_feature==2: # Only cre-up feature\n","            update_v = updateds[v]\n","            cre_up = abs((cre_u - update_v).days)\n","            link_other_features.append([cre_up])\n","          else: # Add all time features (cre_cre, cre_up)\n","            cre_v = createds[v]\n","            cre_cre = abs((cre_u - cre_v).days)\n","            update_v = updateds[v]\n","            cre_up = abs((cre_u - update_v).days)\n","            link_other_features.append([cre_cre, cre_up])\n","\n","\n","    # Get non_link_data\n","    for index in tqdm(non_link_data_index):\n","        p = pairs[index]\n","        u = int(p[0])\n","        v = int(p[1])\n","        \n","        cre_u = createds[u]\n","        \n","        if add_feature==1:\n","          cre_v = createds[v]\n","          cre_cre = abs((cre_u - cre_v).days)\n","          non_link_other_features.append([cre_cre])\n","        else:\n","          if add_feature==2:\n","            update_v = updateds[v]\n","            cre_up = abs((cre_u - update_v).days)\n","            non_link_other_features.append([cre_up])\n","          else:\n","            cre_v = createds[v]\n","            cre_cre = abs((cre_u - cre_v).days)\n","            update_v = updateds[v]\n","            cre_up = abs((cre_u - update_v).days)\n","            non_link_other_features.append([cre_cre, cre_up])\n","\n","    return link_data, non_link_data, link_other_features, non_link_other_features\n","    \n","  return link_data, non_link_data"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBmDwa9GmDaD","executionInfo":{"status":"ok","timestamp":1630142294026,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def generate_input(config_generator, train_input):\n","  batch_size, mul, add_feature = config_generator\n","  all_textual_vectors, link_data, non_link_data, link_other_features, non_link_other_features = train_input\n","  while True:\n","    each_size = int(batch_size/2)\n","    \n","    # Shuffle index of link data\n","    shuffle_index = [index for index in np.random.choice(len(link_data), len(link_data), replace=False)]\n","    link_data = [link_data[index] for index in shuffle_index]\n","    \n","    if add_feature!=None:\n","      link_other_features = [link_other_features[index] for index in shuffle_index]\n","\n","    for iter in range(int(len(link_data)/each_size)):\n","        # Split data by batch size and randomly select non_link_data: 1/2 for link data, 1/2 for unlink data\n","        \n","        # Get index\n","        link_index = np.array(range(iter*each_size, (iter+1)*each_size))\n","        non_link_index = np.array([index for index in np.random.choice(len(non_link_data), each_size*mul, replace=False)])\n","        \n","        link_X = [link_data[i] for i in link_index]\n","        non_link_X = [non_link_data[i] for i in non_link_index]\n","        \n","        # Create X by tokenizing and padding X\n","        X = np.array(link_X + non_link_X)\n","        padded_A = all_textual_vectors[X[:,0]]\n","        padded_B = all_textual_vectors[X[:,1]]\n","\n","        # Create label y\n","        link_y = np.vstack([np.zeros(len(link_X)), np.ones(len(link_X))]).T\n","        non_link_y = np.vstack([np.ones(len(link_X)), np.zeros(len(link_X))]).T\n","        y = np.concatenate([link_y, non_link_y])\n","                \n","        index = np.random.choice(batch_size, batch_size, replace=False)\n","        if add_feature!=None:\n","          # Create other features\n","          link_other_X = np.array([link_other_features[\u001di] for i in link_index])\n","          non_link_other_X = np.array([non_link_other_features[i] for i in non_link_index])\n","          other_features = np.concatenate([link_other_X, non_link_other_X])\n","          yield [padded_A[index], padded_B[index], other_features[index]], y[index]\n","        else:\n","          yield [padded_A[index], padded_B[index]], y[index]\n","  return 0"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99ILnvh8hlKw"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"k9vYWqKHhlK3","executionInfo":{"status":"ok","timestamp":1630142294027,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def return_model(input_init, add_feature):\n","  value_maxlen, number_units, lr, l = input_init\n","  inputs_A = tf.keras.Input(shape=(value_maxlen, 300), name=\"input_a\")\n","  inputs_B = tf.keras.Input(shape=(value_maxlen, 300), name=\"input_b\")\n","\n","  if add_feature==1 or add_feature==2:\n","    inputs_C = tf.keras.Input(shape=(1), name=\"input_c\")\n","  else:\n","    inputs_C = tf.keras.Input(shape=(2), name=\"input_c\")\n","\n","  # Deep Learning model's structure\n","  cnn_layer = tf.keras.layers.Conv1D(number_units, 3, activation='relu')\n","  flatten_layer = tf.keras.layers.Flatten(name=\"flatten\")\n","  dense_1_layer = tf.keras.layers.Dense(number_units, activation=\"relu\", name=\"dense_1\")\n","  output_layer = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"dense_output\")\n","\n","  # cnn\n","  cnn_A = cnn_layer(inputs_A)\n","  cnn_B = cnn_layer(inputs_B)\n","\n","  if add_feature==None:\n","  \n","    # Concat two embedded inputs\n","    X = tf.concat([flatten_layer(cnn_A), flatten_layer(cnn_B)], axis=1)\n","  \n","    dense_1_X = dense_1_layer(X)\n","  \n","    outputs = output_layer(dense_1_X)\n","  \n","    model = tf.keras.Model(inputs=[inputs_A, inputs_B], outputs=outputs)\n","  \n","  else:\n","  \n","    # Concat two embedded inputs\n","    X = tf.concat([flatten_layer(cnn_A), flatten_layer(cnn_B), inputs_C], axis=1)\n","  \n","    dense_1_X = dense_1_layer(X)\n","  \n","    outputs = output_layer(dense_1_X)\n","  \n","    model = tf.keras.Model(inputs=[inputs_A, inputs_B, inputs_C], outputs=outputs)\n","\n","  model.compile(tf.keras.optimizers.Adam(learning_rate=lr), loss=l, metrics=[\"categorical_accuracy\"])  \n","  model.summary()\n","\n","  return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5UfrUyiChlK4","executionInfo":{"status":"ok","timestamp":1630142294028,"user_tz":-420,"elapsed":28,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def train_model(model_params, init_input, train_input):\n","  steps_per_epoch, epochs, batch_size, add_feature = model_params\n","  model_path, value_maxlen, model, all_textual_vectors = init_input\n","  links_train, non_links_train, links_other_features_train, non_links_other_features_train = train_input\n","  \n","  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = model_path, save_best_only=True,save_weights_only=True)\n","  \n","  # Config generator\n","  batch_size = 64\n","  mul = 3\n","  config_generator = (batch_size, mul, add_feature)\n","  train_input = all_textual_vectors, links_train, non_links_train, links_other_features_train, non_links_other_features_train\n","  history = model.fit(generate_input(config_generator, train_input), \n","              steps_per_epoch=steps_per_epoch, \n","              epochs=epochs,\n","              shuffle=False,\n","              callbacks=[model_checkpoint_callback],\n","              verbose = 1)\n","  return history"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1WHra7QvUs1"},"source":["## Recommend"]},{"cell_type":"code","metadata":{"id":"DZUEKauLZIDL","executionInfo":{"status":"ok","timestamp":1630142294029,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def model_predict(init_input, data_test, labels_test, other_features):\n","  value_maxlen, model, all_textual_vectors = init_input\n","  y_s = np.empty((2,2))\n","  pred_s = np.empty((2,2))\n","\n","  each_size = len(data_test) #all dataset\n","  \n","  t = 0\n","  while t<each_size:\n","    if t+2048 < each_size:\n","      data_X = data_test[t:t+2048]\n","    else:\n","      data_X = data_test[t:]\n","\n","    X = np.array(data_X)\n","    padded_A = all_textual_vectors[X[:,0]]\n","    padded_B = all_textual_vectors[X[:,1]]\n","    \n","    # Create label y\n","    if t+2048 < each_size:\n","      y = labels_test[t:t+2048]\n","    else:\n","      y = labels_test[t:]\n","\n","    if type(other_features) is np.ndarray:\n","      # Create features\n","      if t+2048 < each_size:\n","        test_features = other_features[t:t+2048]\n","      else:\n","        test_features = other_features[t:]\n","      pred = model.predict([padded_A, padded_B, test_features])\n","    else:\n","      pred = model.predict([padded_A, padded_B])\n","    \n","    del padded_A\n","    del padded_B\n","    gc.collect()\n","    \n","    y_s = np.concatenate([y_s, y])\n","    del y\n","    gc.collect()\n","    pred_s = np.concatenate([pred_s, pred])\n","    del pred\n","    gc.collect()\n","\n","    t+=2048\n","\n","    print(t,'/',each_size)\n","\n","  # Delete empty value in y_s and pred_s\n","  y_s = y_s[2:]\n","  pred_s = pred_s[2:]\n","\n","  # Get label\n","  y_s = np.argmax(y_s, axis=1)\n","\n","  pred_proba = np.array(pred_s)[:,1] # Proba of having link\n","\n","  pred_s = np.argmax(pred_s, axis=1)\n","\n","  return y_s, pred_s, pred_proba"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5WzzLMOUxEzP"},"source":["### Evaluate"]},{"cell_type":"code","metadata":{"id":"DczN9t57kD3i","executionInfo":{"status":"ok","timestamp":1630142294030,"user_tz":-420,"elapsed":29,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def get_test_data(input, add_feature=None):\n","    print('Get testing data pairs')\n","    pairs, labels, createds, updateds = input\n","    data = []\n","    test_labels = []\n","    other_features = []\n","\n","    # Get link_data_sample\n","    for index in tqdm(range(len(pairs))):\n","        p = pairs[index]\n","        u = int(p[0])\n","        v = int(p[1])\n","        data.append([u, v])\n","        test_labels.append(labels[index])\n","        if add_feature != None:\n","          cre_u = createds[u]\n","          cre_v = createds[v]\n","          update_v = updateds[v]\n","          cre_cre = abs((cre_u - cre_v).days)\n","          cre_up = abs((cre_u - update_v).days)\n","          if add_feature==1:\n","            other_features.append([cre_cre])\n","          else:\n","            if add_feature==2:\n","              other_features.append([cre_up])\n","            else:\n","              other_features.append([cre_cre, cre_up])\n","        else:\n","          other_features = None\n","    if add_feature!=None:\n","      other_features = np.array(other_features)\n","      return data, test_labels, other_features\n","    else:\n","      return data, test_labels"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"KngCr1VHh6_9","executionInfo":{"status":"ok","timestamp":1630142294673,"user_tz":-420,"elapsed":672,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def evaluate(y_s, pred_s):\n","  m = tf.keras.metrics.Accuracy()\n","  m.update_state(y_s, pred_s)\n","  print(m.result().numpy())\n","\n","  from sklearn.metrics import confusion_matrix, classification_report\n","  print(\"Confusion maxtrix\")\n","  print(confusion_matrix(y_s, pred_s))\n","  print(classification_report(y_s, pred_s, digits= 2))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sb26mmnxCbmZ"},"source":["### Recommend"]},{"cell_type":"code","metadata":{"id":"teDWebiyyA9k","executionInfo":{"status":"ok","timestamp":1630142294674,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def recommend_function(createds, test_nodes, test_pairs, pred_proba):\n","  total_size = len(test_nodes)\n","\n","  recommend_s = []\n","  for i in range(total_size):\n","    recommend_s.append([])\n","\n","  \n","  # Make dictionary of test_nodes and position of test_nodes in list\n","  index_dictionary = dict(zip(test_nodes, range(total_size)))\n","\n","  print('Make recommends!')\n","  for iter in tqdm(range(len(test_pairs))):\n","    pair = test_pairs[iter]\n","    u = int(pair[0])\n","    v = int(pair[1])\n","    if abs((createds[u]-createds[v]).days)<=60:\n","      proba = pred_proba[iter] \n","      if u in index_dictionary.keys():\n","        index_1 = index_dictionary[u]     \n","        index_2 = v \n","        recommend_s[index_1].append((index_2,proba))\n","      \n","      if v in index_dictionary.keys():\n","        index_1 = index_dictionary[v]     \n","        index_2 = u\n","        recommend_s[index_1].append((index_2,proba))\n","\n","  return recommend_s"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGoii9pcSOVS","executionInfo":{"status":"ok","timestamp":1630142294675,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def Acc(pred, gt):\n","\tacc = 0\n","\tfor i, item in enumerate(pred):\n","\t\tif item in gt:\n","\t\t\tacc += 1.0 \n","\t\t\tbreak\n","\treturn acc"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VO5U9mwyCZGR","executionInfo":{"status":"ok","timestamp":1630142294675,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def MRR(pred, gt):\n","\tmrr = 0\n","\tfor i, item in enumerate(pred):\n","\t\tif item in gt:\n","\t\t\tmrr += 1.0/(i+1) \n","\treturn mrr"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJ5_Y13sZ1zq","executionInfo":{"status":"ok","timestamp":1630142294676,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def Precision_Recall(pred, gt):\n","  right = 0\n","  \n","  for item in gt:\n","    if item in pred: # relevant\n","      right+=1\n","\n","  if len(pred) == 0:\n","    precision = 0\n","  else:\n","    precision = right/len(pred)\n","  recall = right/len(gt)\n","  \n","  return precision, recall"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3zxc2kUB_Qk","executionInfo":{"status":"ok","timestamp":1630142294677,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def metrics(recommend, label):\n","  acc = 0\n","  mrr = 0\n","  precision = 0\n","  recall = 0\n","  for i in range(0, len(recommend)):\n","    if len(label[i])!=0:\n","      acc+=Acc(recommend[i], label[i])\n","      mrr+=MRR(recommend[i], label[i])\n","      precision_recall = Precision_Recall(recommend[i], label[i])\n","      precision+=precision_recall[0]\n","      recall+=precision_recall[1]\n","  return acc/(len(recommend)), mrr/(len(recommend)), precision/(len(recommend)), recall/(len(recommend))"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCPd8rldIoAF"},"source":["### List of recommend"]},{"cell_type":"code","metadata":{"id":"J90oyNipGidm","executionInfo":{"status":"ok","timestamp":1630142294679,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["def get_result(project_name, path, input):\n","  createds, test_nodes, all_nodes, test_pairs, pred_proba = input\n","  recommend_s = recommend_function(createds, test_nodes, test_pairs, pred_proba)\n","  \n","\n","  # Sort nodes in pairs\n","  recommend_s2 = []\n","  c = 0\n","  for recommend2 in recommend_s:\n","    c+=1\n","    recommend = np.array(sorted(recommend2, key = lambda x: x[1], reverse = True))\n","    if len(recommend)>0:\n","      recommend = np.array(recommend[:,0], dtype = int)\n","    recommend_s2.append(recommend)\n","\n","  y_test = []\n","\n","  for i in range(len(test_nodes)):\n","    nodes = []\n","    for j in range(len(all_nodes)):\n","      if graph[test_nodes[i], all_nodes[j]][1] !=0 and graph[test_nodes[i], all_nodes[j]][1] !=0:\n","        nodes.append(all_nodes[j])\n","    y_test.append(nodes)\n","  \n","  f = open(path, \"a\")\n","  \n","\n","  top = 1\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 1:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 2\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 2:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 3\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 3:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 5\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 5:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 10\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 10:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 20\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 20:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 30\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 30:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 50\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 50:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","  f.close()"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAk3ZnP8QTMY"},"source":["# Main program"]},{"cell_type":"markdown","metadata":{"id":"02oiSc4QQwlA"},"source":["### Start"]},{"cell_type":"code","metadata":{"id":"nxT9qdSmQhbi","executionInfo":{"status":"ok","timestamp":1630142294680,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}}},"source":["list_project_names = [('FLUME', 1577, 5, 200, 256)]\n","list_chosen_textual_features = [['title', 'summary']]\n","list_add_features = [3]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaIYllMIsa5b","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1630144481473,"user_tz":-420,"elapsed":2186806,"user":{"displayName":"Ảo Nick","photoUrl":"","userId":"06417530121208925554"}},"outputId":"6940bf2f-cd36-4aef-acbf-9c3b79991c3f"},"source":["number = -1\n","for project in list_project_names:\n","  number+=1\n","  project_name = project[0]\n","  time_split = project[1]\n","\n","  # Model params\n","  steps_per_epoch = project[2]\n","  epochs = project[3]\n","  batch_size = project[4]\n","\n","  # Load dataset\n","  df, graph = load_project(project_name)\n","\n","  # Split data\n","  createds, updateds = get_time_features(df)\n","  train_nodes, test_nodes, all_nodes = split_data(createds, graph, time_split)\n","\n","  # Pairing\n","  print('Pairing data!')\n","  train_pairs, train_labels = get_pairs(graph, train_nodes, train_nodes)\n","  test_pairs, test_labels = get_pairs(graph, test_nodes, all_nodes)\n","\n","  # Get features\n","\n","  for textual_features in list_chosen_textual_features:\n","    all_textual_vectors = get_textual_features(df, textual_features)\n","    value_maxlen = all_textual_vectors.shape[1]\n","    for add_feature in list_add_features:\n","      # Model  \n","      if add_feature!=None:    \n","        links_train, non_links_train, link_other_features, non_link_other_features = get_separated_data_pairs([train_pairs, train_labels, createds, updateds], add_feature)\n","        train_other_features = np.concatenate([link_other_features, non_link_other_features])\n","        mean = np.mean(train_other_features)\n","        std = np.std(train_other_features)\n","        link_other_features = np.array([(link_other_features[i]-mean)/std for i in range(0, len(links_train))])\n","        non_link_other_features = np.array([(non_link_other_features[i]-mean)/std for i in range(0, len(non_links_train))])\n","        data_test, labels_test, other_features = get_test_data([test_pairs, test_labels, createds, updateds], add_feature)\n","        other_features = np.array([(other_features[i]-mean)/std for i in range(0, len(other_features))])\n","      else:\n","        links_train, non_links_train = get_separated_data_pairs([train_pairs, train_labels, createds, updateds], add_feature)\n","        data_test, labels_test = get_test_data([test_pairs, test_labels, createds, updateds], add_feature)\n","\n","      if add_feature!=None:\n","        del train_other_features\n","        gc.collect() \n","\n","      result_path = '{}_Test_GloVe_CNN_3_Post.txt'.format(project_name)\n","      param, lr, l = 256, 1e-3, 'mse'\n","      f = open(result_path, \"a\")\n","      listToStr = ' '.join([str(elem) for elem in textual_features]) \n","      listToStr = listToStr + ' ' + repr(add_feature)\n","      f.write(listToStr)\n","      f.write('\\n')\n","      if add_feature!=None:\n","        f.write('\\n')\n","        f.write('mean = ' + repr(mean) + '\\n')\n","        f.write('std = ' + repr(std) + '\\n')\n","      f.close()\n","\n","      model = return_model([value_maxlen, param, lr, l], add_feature)\n","\n","      # Train model\n","      model_path = project_name + '_GloVe_CNN_3_' + str(number) + str(lr) + str(l) + '.h5'\n","      print('Training model...')\n","      if add_feature == None:\n","        history = train_model([steps_per_epoch, epochs, batch_size, add_feature], [model_path, value_maxlen, model, all_textual_vectors], [links_train, non_links_train, None, None])\n","      else:\n","        history = train_model([steps_per_epoch, epochs, batch_size, add_feature], [model_path, value_maxlen, model, all_textual_vectors], [links_train, non_links_train, link_other_features, non_link_other_features])\n","\n","      # summarize history for accuracy\n","      plt.plot(history.history['categorical_accuracy'])\n","      plt.title('model accuracy')\n","      plt.ylabel('accuracy')\n","      plt.xlabel('epoch')\n","      plt.legend(['train', 'test'], loc='upper left')\n","      plt.savefig(project_name + \"_GloVe_CNN_3_\" + str(number) + str(l) + \"_accuracy.png\", dpi=1200)\n","\n","      # summarize history for loss\n","      plt.plot(history.history['loss'])\n","      plt.title('model loss')\n","      plt.ylabel('loss')\n","      plt.xlabel('epoch')\n","      plt.legend(['train', 'test'], loc='upper left')\n","      plt.savefig(project_name + \"_GloVe_CNN_3_\" + str(number) + str(l) + \"_loss.png\", dpi=1200)\n","\n","      # Test model\n","      if add_feature!=None:\n","        y_s, pred_s, pred_proba = model_predict([value_maxlen, model, all_textual_vectors], data_test, labels_test, other_features)\n","      else:\n","        y_s, pred_s, pred_proba = model_predict([value_maxlen, model, all_textual_vectors], data_test, labels_test, None)\n","      evaluate(y_s, pred_s)\n","      get_result(project_name, result_path, [createds, test_nodes, all_nodes, test_pairs, pred_proba])\n","      np.savez(project_name + '_GloVe_CNN_3_' + str(number) + \"y\", y_s = y_s, pred_s = pred_s, pred_proba = pred_proba)\n","\n","      del y_s\n","      del pred_s\n","      del model\n","      gc.collect()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Pairing data!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2502/2502 [00:18<00:00, 133.20it/s]\n","100%|██████████| 227/227 [00:01<00:00, 121.48it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Loading title\n","Loading summary\n","Get training data pairs\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1266/1266 [00:00<00:00, 328568.09it/s]\n","100%|██████████| 6256236/6256236 [00:10<00:00, 591153.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Get time features!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1266/1266 [00:00<00:00, 17181.59it/s]\n","100%|██████████| 6256236/6256236 [05:55<00:00, 17591.27it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Get testing data pairs\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 619256/619256 [00:34<00:00, 18117.80it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_a (InputLayer)            [(None, 40, 300)]    0                                            \n","__________________________________________________________________________________________________\n","input_b (InputLayer)            [(None, 40, 300)]    0                                            \n","__________________________________________________________________________________________________\n","conv1d (Conv1D)                 (None, 38, 256)      230656      input_a[0][0]                    \n","                                                                 input_b[0][0]                    \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 9728)         0           conv1d[0][0]                     \n","                                                                 conv1d[1][0]                     \n","__________________________________________________________________________________________________\n","input_c (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","tf.concat (TFOpLambda)          (None, 19458)        0           flatten[0][0]                    \n","                                                                 flatten[1][0]                    \n","                                                                 input_c[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 256)          4981504     tf.concat[0][0]                  \n","__________________________________________________________________________________________________\n","dense_output (Dense)            (None, 2)            514         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 5,212,674\n","Trainable params: 5,212,674\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Training model...\n","Epoch 1/200\n","5/5 [==============================] - 16s 202ms/step - loss: 0.3027 - categorical_accuracy: 0.5531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 2/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.2690 - categorical_accuracy: 0.5719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 3/200\n","5/5 [==============================] - 1s 158ms/step - loss: 0.2383 - categorical_accuracy: 0.6125\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 4/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.2335 - categorical_accuracy: 0.6469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 5/200\n","5/5 [==============================] - 1s 253ms/step - loss: 0.2082 - categorical_accuracy: 0.6562\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 6/200\n","5/5 [==============================] - 1s 254ms/step - loss: 0.2012 - categorical_accuracy: 0.6969\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 7/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.1912 - categorical_accuracy: 0.7094\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 8/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.1692 - categorical_accuracy: 0.7625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 9/200\n","5/5 [==============================] - 1s 206ms/step - loss: 0.1411 - categorical_accuracy: 0.8031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 10/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.1324 - categorical_accuracy: 0.8375\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 11/200\n","5/5 [==============================] - 1s 203ms/step - loss: 0.1362 - categorical_accuracy: 0.8031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 12/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.1146 - categorical_accuracy: 0.8500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 13/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.1405 - categorical_accuracy: 0.7969\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 14/200\n","5/5 [==============================] - 1s 203ms/step - loss: 0.1277 - categorical_accuracy: 0.8219\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 15/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.1249 - categorical_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 16/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.1249 - categorical_accuracy: 0.8344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 17/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0923 - categorical_accuracy: 0.8687\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 18/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0809 - categorical_accuracy: 0.9031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 19/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.1079 - categorical_accuracy: 0.8406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 20/200\n","5/5 [==============================] - 1s 201ms/step - loss: 0.1242 - categorical_accuracy: 0.8281\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 21/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0910 - categorical_accuracy: 0.8844\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 22/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.1218 - categorical_accuracy: 0.8250\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 23/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.1139 - categorical_accuracy: 0.8500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 24/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.1119 - categorical_accuracy: 0.8594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 25/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0828 - categorical_accuracy: 0.8844\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 26/200\n","5/5 [==============================] - 1s 268ms/step - loss: 0.0786 - categorical_accuracy: 0.9156\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 27/200\n","5/5 [==============================] - 1s 261ms/step - loss: 0.0781 - categorical_accuracy: 0.9094\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 28/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0945 - categorical_accuracy: 0.8844\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 29/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0833 - categorical_accuracy: 0.8844\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 30/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0971 - categorical_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 31/200\n","5/5 [==============================] - 1s 204ms/step - loss: 0.0828 - categorical_accuracy: 0.8938\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 32/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0693 - categorical_accuracy: 0.9312\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 33/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0601 - categorical_accuracy: 0.9187\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 34/200\n","5/5 [==============================] - 1s 153ms/step - loss: 0.0631 - categorical_accuracy: 0.9094\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 35/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0652 - categorical_accuracy: 0.9125\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 36/200\n","5/5 [==============================] - 1s 204ms/step - loss: 0.0639 - categorical_accuracy: 0.9187\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 37/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0703 - categorical_accuracy: 0.9125\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 38/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0815 - categorical_accuracy: 0.9000\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 39/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0713 - categorical_accuracy: 0.9000\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 40/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0605 - categorical_accuracy: 0.9125\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 41/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0634 - categorical_accuracy: 0.9187\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 42/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0679 - categorical_accuracy: 0.9031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 43/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0597 - categorical_accuracy: 0.9125\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 44/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0670 - categorical_accuracy: 0.9031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 45/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0742 - categorical_accuracy: 0.8938\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 46/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0595 - categorical_accuracy: 0.9219\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 47/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0621 - categorical_accuracy: 0.9250\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 48/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0590 - categorical_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 49/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0492 - categorical_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 50/200\n","5/5 [==============================] - 1s 206ms/step - loss: 0.0479 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 51/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0725 - categorical_accuracy: 0.8875\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 52/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0561 - categorical_accuracy: 0.9250\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 53/200\n","5/5 [==============================] - 1s 261ms/step - loss: 0.0576 - categorical_accuracy: 0.9312\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 54/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0574 - categorical_accuracy: 0.9281\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 55/200\n","5/5 [==============================] - 1s 203ms/step - loss: 0.0586 - categorical_accuracy: 0.9219\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 56/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0396 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 57/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0438 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 58/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0454 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 59/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0634 - categorical_accuracy: 0.9000\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 60/200\n","5/5 [==============================] - 1s 214ms/step - loss: 0.0719 - categorical_accuracy: 0.9031\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 61/200\n","5/5 [==============================] - 1s 254ms/step - loss: 0.0691 - categorical_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 62/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0879 - categorical_accuracy: 0.8906\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 63/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0775 - categorical_accuracy: 0.9094\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 64/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0529 - categorical_accuracy: 0.9250\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 65/200\n","5/5 [==============================] - 1s 199ms/step - loss: 0.0440 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 66/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0438 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 67/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0512 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 68/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0530 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 69/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0465 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 70/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0726 - categorical_accuracy: 0.9000\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 71/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0402 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 72/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0457 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 73/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0361 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 74/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0489 - categorical_accuracy: 0.9312\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 75/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0401 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 76/200\n","5/5 [==============================] - 1s 203ms/step - loss: 0.0692 - categorical_accuracy: 0.9000\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 77/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0417 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 78/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0440 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 79/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0481 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 80/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0402 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 81/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0376 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 82/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0456 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 83/200\n","5/5 [==============================] - 1s 256ms/step - loss: 0.0517 - categorical_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 84/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0311 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 85/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0549 - categorical_accuracy: 0.9281\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 86/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0394 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 87/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0602 - categorical_accuracy: 0.9281\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 88/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0397 - categorical_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 89/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0356 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 90/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0451 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 91/200\n","5/5 [==============================] - 1s 222ms/step - loss: 0.0437 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 92/200\n","5/5 [==============================] - 1s 253ms/step - loss: 0.0403 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 93/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0434 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 94/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0448 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 95/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0290 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 96/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0288 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 97/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0457 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 98/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0469 - categorical_accuracy: 0.9312\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 99/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0370 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 100/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0434 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 101/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0333 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 102/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0596 - categorical_accuracy: 0.9250\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 103/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0593 - categorical_accuracy: 0.9156\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 104/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0384 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 105/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0481 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 106/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0373 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 107/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0453 - categorical_accuracy: 0.9344\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 108/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0362 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 109/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0434 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 110/200\n","5/5 [==============================] - 1s 199ms/step - loss: 0.0473 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 111/200\n","5/5 [==============================] - 1s 254ms/step - loss: 0.0365 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 112/200\n","5/5 [==============================] - 1s 212ms/step - loss: 0.0420 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 113/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0539 - categorical_accuracy: 0.9281\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 114/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0292 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 115/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0227 - categorical_accuracy: 0.9719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 116/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0430 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 117/200\n","5/5 [==============================] - 1s 199ms/step - loss: 0.0421 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 118/200\n","5/5 [==============================] - 1s 201ms/step - loss: 0.0384 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 119/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0333 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 120/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0303 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 121/200\n","5/5 [==============================] - 1s 204ms/step - loss: 0.0423 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 122/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0298 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 123/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0373 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 124/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0371 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 125/200\n","5/5 [==============================] - 1s 256ms/step - loss: 0.0304 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 126/200\n","5/5 [==============================] - 1s 255ms/step - loss: 0.0224 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 127/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0325 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 128/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0337 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 129/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0458 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 130/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0251 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 131/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0351 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 132/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0368 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 133/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0305 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 134/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0276 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 135/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0280 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 136/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0288 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 137/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0231 - categorical_accuracy: 0.9719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 138/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0339 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 139/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0420 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 140/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0331 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 141/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0234 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 142/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0257 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 143/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0335 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 144/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0257 - categorical_accuracy: 0.9719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 145/200\n","5/5 [==============================] - 1s 205ms/step - loss: 0.0302 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 146/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0262 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 147/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0309 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 148/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0483 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 149/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0262 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 150/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0334 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 151/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0478 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 152/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0301 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 153/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0400 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 154/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0139 - categorical_accuracy: 0.9812\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 155/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0251 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 156/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0326 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 157/200\n","5/5 [==============================] - 1s 262ms/step - loss: 0.0374 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 158/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0354 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 159/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0309 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 160/200\n","5/5 [==============================] - 1s 253ms/step - loss: 0.0468 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 161/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0440 - categorical_accuracy: 0.9406\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 162/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0400 - categorical_accuracy: 0.9531\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 163/200\n","5/5 [==============================] - 1s 252ms/step - loss: 0.0319 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 164/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0275 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 165/200\n","5/5 [==============================] - 1s 253ms/step - loss: 0.0339 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 166/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0306 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 167/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0332 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 168/200\n","5/5 [==============================] - 1s 202ms/step - loss: 0.0255 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 169/200\n","5/5 [==============================] - 1s 251ms/step - loss: 0.0334 - categorical_accuracy: 0.9500\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 170/200\n","5/5 [==============================] - 1s 259ms/step - loss: 0.0314 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 171/200\n","5/5 [==============================] - 1s 260ms/step - loss: 0.0222 - categorical_accuracy: 0.9750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 172/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0428 - categorical_accuracy: 0.9438\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 173/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0207 - categorical_accuracy: 0.9781\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 174/200\n","5/5 [==============================] - 1s 249ms/step - loss: 0.0254 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 175/200\n","5/5 [==============================] - 1s 207ms/step - loss: 0.0274 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 176/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0303 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 177/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0218 - categorical_accuracy: 0.9750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 178/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0290 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 179/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0318 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 180/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0198 - categorical_accuracy: 0.9750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 181/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0128 - categorical_accuracy: 0.9875\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 182/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0174 - categorical_accuracy: 0.9812\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 183/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0378 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 184/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0317 - categorical_accuracy: 0.9563\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 185/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0435 - categorical_accuracy: 0.9469\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 186/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0223 - categorical_accuracy: 0.9719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 187/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0256 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 188/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0123 - categorical_accuracy: 0.9844\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 189/200\n","5/5 [==============================] - 1s 162ms/step - loss: 0.0181 - categorical_accuracy: 0.9781\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 190/200\n","5/5 [==============================] - 1s 208ms/step - loss: 0.0201 - categorical_accuracy: 0.9750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 191/200\n","5/5 [==============================] - 1s 247ms/step - loss: 0.0297 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 192/200\n","5/5 [==============================] - 1s 250ms/step - loss: 0.0344 - categorical_accuracy: 0.9625\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 193/200\n","5/5 [==============================] - 1s 248ms/step - loss: 0.0201 - categorical_accuracy: 0.9719\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 194/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0263 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 195/200\n","5/5 [==============================] - 1s 198ms/step - loss: 0.0297 - categorical_accuracy: 0.9594\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 196/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0232 - categorical_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 197/200\n","5/5 [==============================] - 1s 245ms/step - loss: 0.0286 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 198/200\n","5/5 [==============================] - 1s 246ms/step - loss: 0.0269 - categorical_accuracy: 0.9750\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 199/200\n","5/5 [==============================] - 1s 196ms/step - loss: 0.0181 - categorical_accuracy: 0.9812\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","Epoch 200/200\n","5/5 [==============================] - 1s 200ms/step - loss: 0.0285 - categorical_accuracy: 0.9656\n","WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n","2048 / 619256\n","4096 / 619256\n","6144 / 619256\n","8192 / 619256\n","10240 / 619256\n","12288 / 619256\n","14336 / 619256\n","16384 / 619256\n","18432 / 619256\n","20480 / 619256\n","22528 / 619256\n","24576 / 619256\n","26624 / 619256\n","28672 / 619256\n","30720 / 619256\n","32768 / 619256\n","34816 / 619256\n","36864 / 619256\n","38912 / 619256\n","40960 / 619256\n","43008 / 619256\n","45056 / 619256\n","47104 / 619256\n","49152 / 619256\n","51200 / 619256\n","53248 / 619256\n","55296 / 619256\n","57344 / 619256\n","59392 / 619256\n","61440 / 619256\n","63488 / 619256\n","65536 / 619256\n","67584 / 619256\n","69632 / 619256\n","71680 / 619256\n","73728 / 619256\n","75776 / 619256\n","77824 / 619256\n","79872 / 619256\n","81920 / 619256\n","83968 / 619256\n","86016 / 619256\n","88064 / 619256\n","90112 / 619256\n","92160 / 619256\n","94208 / 619256\n","96256 / 619256\n","98304 / 619256\n","100352 / 619256\n","102400 / 619256\n","104448 / 619256\n","106496 / 619256\n","108544 / 619256\n","110592 / 619256\n","112640 / 619256\n","114688 / 619256\n","116736 / 619256\n","118784 / 619256\n","120832 / 619256\n","122880 / 619256\n","124928 / 619256\n","126976 / 619256\n","129024 / 619256\n","131072 / 619256\n","133120 / 619256\n","135168 / 619256\n","137216 / 619256\n","139264 / 619256\n","141312 / 619256\n","143360 / 619256\n","145408 / 619256\n","147456 / 619256\n","149504 / 619256\n","151552 / 619256\n","153600 / 619256\n","155648 / 619256\n","157696 / 619256\n","159744 / 619256\n","161792 / 619256\n","163840 / 619256\n","165888 / 619256\n","167936 / 619256\n","169984 / 619256\n","172032 / 619256\n","174080 / 619256\n","176128 / 619256\n","178176 / 619256\n","180224 / 619256\n","182272 / 619256\n","184320 / 619256\n","186368 / 619256\n","188416 / 619256\n","190464 / 619256\n","192512 / 619256\n","194560 / 619256\n","196608 / 619256\n","198656 / 619256\n","200704 / 619256\n","202752 / 619256\n","204800 / 619256\n","206848 / 619256\n","208896 / 619256\n","210944 / 619256\n","212992 / 619256\n","215040 / 619256\n","217088 / 619256\n","219136 / 619256\n","221184 / 619256\n","223232 / 619256\n","225280 / 619256\n","227328 / 619256\n","229376 / 619256\n","231424 / 619256\n","233472 / 619256\n","235520 / 619256\n","237568 / 619256\n","239616 / 619256\n","241664 / 619256\n","243712 / 619256\n","245760 / 619256\n","247808 / 619256\n","249856 / 619256\n","251904 / 619256\n","253952 / 619256\n","256000 / 619256\n","258048 / 619256\n","260096 / 619256\n","262144 / 619256\n","264192 / 619256\n","266240 / 619256\n","268288 / 619256\n","270336 / 619256\n","272384 / 619256\n","274432 / 619256\n","276480 / 619256\n","278528 / 619256\n","280576 / 619256\n","282624 / 619256\n","284672 / 619256\n","286720 / 619256\n","288768 / 619256\n","290816 / 619256\n","292864 / 619256\n","294912 / 619256\n","296960 / 619256\n","299008 / 619256\n","301056 / 619256\n","303104 / 619256\n","305152 / 619256\n","307200 / 619256\n","309248 / 619256\n","311296 / 619256\n","313344 / 619256\n","315392 / 619256\n","317440 / 619256\n","319488 / 619256\n","321536 / 619256\n","323584 / 619256\n","325632 / 619256\n","327680 / 619256\n","329728 / 619256\n","331776 / 619256\n","333824 / 619256\n","335872 / 619256\n","337920 / 619256\n","339968 / 619256\n","342016 / 619256\n","344064 / 619256\n","346112 / 619256\n","348160 / 619256\n","350208 / 619256\n","352256 / 619256\n","354304 / 619256\n","356352 / 619256\n","358400 / 619256\n","360448 / 619256\n","362496 / 619256\n","364544 / 619256\n","366592 / 619256\n","368640 / 619256\n","370688 / 619256\n","372736 / 619256\n","374784 / 619256\n","376832 / 619256\n","378880 / 619256\n","380928 / 619256\n","382976 / 619256\n","385024 / 619256\n","387072 / 619256\n","389120 / 619256\n","391168 / 619256\n","393216 / 619256\n","395264 / 619256\n","397312 / 619256\n","399360 / 619256\n","401408 / 619256\n","403456 / 619256\n","405504 / 619256\n","407552 / 619256\n","409600 / 619256\n","411648 / 619256\n","413696 / 619256\n","415744 / 619256\n","417792 / 619256\n","419840 / 619256\n","421888 / 619256\n","423936 / 619256\n","425984 / 619256\n","428032 / 619256\n","430080 / 619256\n","432128 / 619256\n","434176 / 619256\n","436224 / 619256\n","438272 / 619256\n","440320 / 619256\n","442368 / 619256\n","444416 / 619256\n","446464 / 619256\n","448512 / 619256\n","450560 / 619256\n","452608 / 619256\n","454656 / 619256\n","456704 / 619256\n","458752 / 619256\n","460800 / 619256\n","462848 / 619256\n","464896 / 619256\n","466944 / 619256\n","468992 / 619256\n","471040 / 619256\n","473088 / 619256\n","475136 / 619256\n","477184 / 619256\n","479232 / 619256\n","481280 / 619256\n","483328 / 619256\n","485376 / 619256\n","487424 / 619256\n","489472 / 619256\n","491520 / 619256\n","493568 / 619256\n","495616 / 619256\n","497664 / 619256\n","499712 / 619256\n","501760 / 619256\n","503808 / 619256\n","505856 / 619256\n","507904 / 619256\n","509952 / 619256\n","512000 / 619256\n","514048 / 619256\n","516096 / 619256\n","518144 / 619256\n","520192 / 619256\n","522240 / 619256\n","524288 / 619256\n","526336 / 619256\n","528384 / 619256\n","530432 / 619256\n","532480 / 619256\n","534528 / 619256\n","536576 / 619256\n","538624 / 619256\n","540672 / 619256\n","542720 / 619256\n","544768 / 619256\n","546816 / 619256\n","548864 / 619256\n","550912 / 619256\n","552960 / 619256\n","555008 / 619256\n","557056 / 619256\n","559104 / 619256\n","561152 / 619256\n","563200 / 619256\n","565248 / 619256\n","567296 / 619256\n","569344 / 619256\n","571392 / 619256\n","573440 / 619256\n","575488 / 619256\n","577536 / 619256\n","579584 / 619256\n","581632 / 619256\n","583680 / 619256\n","585728 / 619256\n","587776 / 619256\n","589824 / 619256\n","591872 / 619256\n","593920 / 619256\n","595968 / 619256\n","598016 / 619256\n","600064 / 619256\n","602112 / 619256\n","604160 / 619256\n","606208 / 619256\n","608256 / 619256\n","610304 / 619256\n","612352 / 619256\n","614400 / 619256\n","616448 / 619256\n","618496 / 619256\n","620544 / 619256\n","0.99106187\n","Confusion maxtrix\n","[[613605   5301]\n"," [   234    116]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00    618906\n","           1       0.02      0.33      0.04       350\n","\n","    accuracy                           0.99    619256\n","   macro avg       0.51      0.66      0.52    619256\n","weighted avg       1.00      0.99      0.99    619256\n","\n","Make recommends!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 619256/619256 [00:20<00:00, 29885.75it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}]}