{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Euclidean_Distance.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QENbYDg4EiTP"},"source":["### Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-roDJlWEJktA","executionInfo":{"status":"ok","timestamp":1634438804347,"user_tz":-420,"elapsed":493,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}},"outputId":"fe8e1b93-dbf6-4f3f-b595-f5ada3958266"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"ZlAT2Wl8J0gD","executionInfo":{"status":"ok","timestamp":1634438805395,"user_tz":-420,"elapsed":604,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import networkx as nx\n","import datetime\n","from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n","import math\n","import time"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62RlHj7UIrne","executionInfo":{"status":"ok","timestamp":1634438805396,"user_tz":-420,"elapsed":25,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}},"outputId":"91318037-6f58-4d4d-a310-dff1dfdc3820"},"source":["cd /content/drive/MyDrive/AISIA/Jira recommendation/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AISIA/Jira recommendation\n"]}]},{"cell_type":"markdown","metadata":{"id":"MTlk8R4WfvUu"},"source":["# Load dataset"]},{"cell_type":"code","metadata":{"id":"WUAyPH7y26Cc","executionInfo":{"status":"ok","timestamp":1634438805397,"user_tz":-420,"elapsed":22,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def encode_graph(row):\n","  new_row = []\n","  for i in row:\n","    if i==0:\n","      new_row.append([1,0])\n","    else:\n","      new_row.append([0,1])\n","  return new_row"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0vt5UFbuSQ1","executionInfo":{"status":"ok","timestamp":1634438805399,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def load_project(project_name):\n","  # Attributes\n","  df = pd.read_csv('data/{}/attribute_preprocess.csv'.format(project_name))\n","  df = df.fillna('')\n","  # Graph\n","  graph = pd.read_csv('data/{}/graph.csv'.format(project_name), delimiter=',')\n","  graph = graph.apply(encode_graph)\n","  graph = graph.values\n","  return df, graph"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8IhkpwRHob0R"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"Ly-enb4GP03f"},"source":["### Get features"]},{"cell_type":"code","metadata":{"id":"0uKrgeS9HkpU","executionInfo":{"status":"ok","timestamp":1634438805400,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def get_string_feature(df):\n","  df[\"title\"] = df[\"title\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","  df[\"description\"] = df[\"description\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","  df[\"summary\"] = df[\"summary\"].str.replace(\"[ ]+\", \" \", regex=True).str.strip()\n","\n","  # Extract data from dataframe\n","  title = df['title'].values\n","  description = df['description'].values\n","  summary = df['summary'].values\n","\n","  return title, description, summary"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4rafYfQTGCR","executionInfo":{"status":"ok","timestamp":1634438805401,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def get_time_features(df):\n","  createds = pd.to_datetime(df['created'])\n","  updateds = pd.to_datetime(df['updated'])\n","  return [createds, updateds]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WdaXoWHxvKkw"},"source":["### Split data"]},{"cell_type":"code","metadata":{"id":"UX3KbV9xHScF","executionInfo":{"status":"ok","timestamp":1634438805402,"user_tz":-420,"elapsed":25,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def split_data(createds, graph, time_split):\n","  # Get date to split data\n","  x = createds[0]\n","  check_date = x + abs(datetime.timedelta(time_split))\n","\n","  train_nodes = []\n","  test_nodes = []\n","\n","  for i in range(0, len(createds)):\n","    if createds[i]<=check_date:\n","      train_nodes.append(i)\n","    else:\n","      test_nodes.append(i) \n","\n","  # Delete all lonely nodes in test\n","  c = 0\n","  new_test_node = []\n","  for i in test_nodes:\n","    t = True\n","    for j in graph[i,:]:\n","      if j[1]!=0: # has linked\n","        t = False\n","    if not t:\n","      c+=1\n","      new_test_node.append(i)\n","\n","  test_nodes = new_test_node\n","  all_nodes = train_nodes + test_nodes\n","\n","  return train_nodes, test_nodes, all_nodes"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLJSQvOweO8T"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"ak4kwhPFeO8h"},"source":["### Pairing"]},{"cell_type":"code","metadata":{"id":"AS-10zImeO8h","executionInfo":{"status":"ok","timestamp":1634438805402,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def get_pairs(graph, list_nodes_1, list_nodes_2):\n","  # list_nodes_1: list of nodes in input\n","  # list_nodes_2: list of nodes in dataset\n","\n","  # Get size\n","  size_1 = len(list_nodes_1)\n","  size_2 = len(list_nodes_2)\n","\n","  # Get index of pairs\n","  pairs = np.empty((size_1*size_2,2))\n","  # Get label\n","  labels = np.empty((size_1*size_2,2))\n","\n","  c=0\n","  for i in tqdm(range(0, size_1)):\n","    for j in range(0, size_2):\n","      u = list_nodes_1[i]\n","      v = list_nodes_2[j]\n","      if u!=v:\n","        # Get index of pairs\n","        pairs[c] = [u,v]\n","        # Get label\n","        labels[c] = graph[u][v]\n","        c+=1\n","\n","  pairs = pairs[:c]\n","  labels = labels[:c]\n","  return pairs, labels"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwIOfrgLup2D","executionInfo":{"status":"ok","timestamp":1634438805403,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def get_data_pairs(pair, all_vectors):\n","  from sklearn.metrics.pairwise import euclidean_distances\n","  data = []\n","  c = 0\n","  for index in tqdm(range(len(pair))):\n","    p = pair[index]\n","    u = int(p[0])\n","    v = int(p[1])\n","    input_A = [all_vectors[u]]\n","    input_B = [all_vectors[v]]\n","    data.append(euclidean_distances(input_A, input_B))\n","    c+=1\n","\n","  return data"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1WHra7QvUs1"},"source":["## Recommend"]},{"cell_type":"code","metadata":{"id":"DZUEKauLZIDL","executionInfo":{"status":"ok","timestamp":1634438805404,"user_tz":-420,"elapsed":24,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def recommend_function(createds, test_nodes, test_pair, pred_proba):\n","  total_size = len(test_nodes)\n","\n","  recommend_s = []\n","  for i in range(total_size):\n","    recommend_s.append([])\n","\n","  \n","  # Make dictionary of test_nodes and position of test_nodes in list\n","  index_dictionary = dict(zip(test_nodes, range(total_size)))\n","\n","\n","  for iter in tqdm(range(len(test_pair))):\n","    pair = test_pair[iter]\n","    u = int(pair[0])\n","    v = int(pair[1])\n","    if abs((createds[u]-createds[v]).days)<=60:\n","      proba = pred_proba[iter] \n","      if u in index_dictionary.keys():\n","        index_1 = index_dictionary[u]     \n","        index_2 = v \n","        recommend_s[index_1].append((index_2,proba))\n","      \n","      if v in index_dictionary.keys():\n","        index_1 = index_dictionary[v]     \n","        index_2 = u\n","        recommend_s[index_1].append((index_2,proba))\n","\n","  return recommend_s"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YVymWeNV16g","executionInfo":{"status":"ok","timestamp":1634438805404,"user_tz":-420,"elapsed":22,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def Acc(pred, gt):\n","\tacc = 0\n","\tfor i, item in enumerate(pred):\n","\t\tif item in gt:\n","\t\t\tacc += 1.0 \n","\t\t\tbreak\n","\treturn acc"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yy5Ex163V16g","executionInfo":{"status":"ok","timestamp":1634438805405,"user_tz":-420,"elapsed":22,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def MRR(pred, gt):\n","  for i, item in enumerate(pred):\n","\t  if item in gt:\n","\t\t  return 1.0/(i+1)\n","  return 0"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZsEjhZDV16h","executionInfo":{"status":"ok","timestamp":1634438805405,"user_tz":-420,"elapsed":22,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def Precision_Recall(pred, gt):\n","  right = 0\n","  \n","  for item in gt:\n","    if item in pred: # relevant\n","      right+=1\n","\n","  if len(pred) == 0:\n","    precision = 0\n","  else:\n","    precision = right/len(pred)\n","  recall = right/len(gt)\n","  \n","  return precision, recall"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rU0ApLE-LiBc","executionInfo":{"status":"ok","timestamp":1634438805406,"user_tz":-420,"elapsed":22,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def NDCG_score(pred, gt):\n","  positions = []\n","\n","  for index in range(0, len(pred)):\n","    if pred[index] in gt:\n","      positions.append(index+1) # Get positions of right results\n","\n","  if len(positions)==0:\n","    return 0.0\n","\n","  dcg = 0\n","  idcg = 0\n","  ideal_index = 1\n","  for pos in positions:\n","    dcg +=1.0/math.log(pos+1,2) # 1.0 because all true results are the same relevant\n","    idcg +=1.0/math.log(ideal_index+1,2)\n","    ideal_index+=1\n","  return dcg/idcg"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rnx7AF-SV16j","executionInfo":{"status":"ok","timestamp":1634438805406,"user_tz":-420,"elapsed":17,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def metrics(recommend, label):\n","  acc = 0.0\n","  mrr = 0.0\n","  precision = 0.0\n","  recall = 0.0\n","  for i in range(0, len(recommend)):\n","    if len(label[i])!=0:\n","      acc+=Acc(recommend[i], label[i])\n","      mrr+=MRR(recommend[i], label[i])\n","      precision_recall = Precision_Recall(recommend[i], label[i])\n","      precision+=precision_recall[0]\n","      recall+=precision_recall[1]\n","  return acc/(len(recommend)), mrr/(len(recommend)), precision/(len(recommend)), recall/(len(recommend))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r5WiLwvHV16j"},"source":["### List of recommend"]},{"cell_type":"code","metadata":{"id":"J90oyNipGidm","executionInfo":{"status":"ok","timestamp":1634438805790,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["def get_result(input):\n","  project_name, createds, test_nodes, all_nodes, test_pair, pred_proba = input\n","  recommend_s = recommend_function(createds, test_nodes, test_pair, pred_proba)\n","  \n","\n","  # Sort nodes in pairs\n","  recommend_s2 = []\n","  c = 0\n","  for recommend2 in recommend_s:\n","    c+=1\n","    recommend = np.array(sorted(recommend2, key = lambda x: x[1], reverse = False))\n","    if len(recommend)>0:\n","      recommend = np.array(recommend[:,0], dtype = int)\n","    recommend_s2.append(recommend)\n","\n","  y_test = []\n","\n","  for i in tqdm(range(len(test_nodes))):\n","    nodes = []\n","    for j in range(len(all_nodes)):\n","      if graph[test_nodes[i], all_nodes[j]][1] !=0 and graph[test_nodes[i], all_nodes[j]][1] !=0:\n","        nodes.append(all_nodes[j])\n","    y_test.append(nodes)\n","\n","  f = open(\"results/euclidean.txt\", \"a\")\n","  f.write(project_name + '\\n')  \n","\n","  top = 1\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 1:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 2\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 2:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 3\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 3:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 5\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 5:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","\n","  top = 10\n","  recommend_s = np.array(recommend_s2)\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 10:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 20\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 20:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 30\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 30:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  top = 50\n","  recommend_s = np.array(recommend_s2)\n","\n","  recommend_s = [i[:top] for i in recommend_s]\n","\n","  f.write('Top 50:')\n","  f.write('\\n')\n","  metric = metrics(recommend_s, y_test)\n","  f.write('Accuracy = ' + repr(metric[0]))\n","  f.write('\\n')\n","  f.write('MRR = ' + repr(metric[1]))\n","  f.write('\\n')\n","  f.write('Recall = ' + repr(metric[3]))\n","  f.write('\\n')\n","\n","  f.close()"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAk3ZnP8QTMY"},"source":["# Main program"]},{"cell_type":"markdown","metadata":{"id":"02oiSc4QQwlA"},"source":["### Start"]},{"cell_type":"code","metadata":{"id":"nxT9qdSmQhbi","executionInfo":{"status":"ok","timestamp":1634438805791,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":["list_project_names = [('FLUME', 1577, 5, 200, 256), ('MDLSITE', 4100, 12, 200, 256)]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_ld41du20MU","executionInfo":{"status":"ok","timestamp":1634440673071,"user_tz":-420,"elapsed":1867284,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}},"outputId":"698e732a-0a99-4d4d-9231-2145de1c0693"},"source":["for project in list_project_names:\n","  project_name = project[0]\n","  time_split = project[1]\n","\n","  # Load dataset\n","  df, graph = load_project(project_name)\n","\n","  # Split data\n","  createds, updateds = get_time_features(df)\n","  train_nodes, test_nodes, all_nodes = split_data(createds, graph, time_split)\n","\n","  # Pairing\n","  test_pair, test_label = get_pairs(graph, test_nodes, all_nodes)\n","\n","  # Get string features\n","  title, description, summary = get_string_feature(df)\n","\n","  train_title = [title[i] for i in train_nodes]\n","  train_description = [description[i] for i in train_nodes]\n","  train_summary = [summary[i] for i in train_nodes]\n","\n","  # Tfidf\n","  tfidf_title = TfidfVectorizer()\n","  tfidf_title.fit(train_title)\n","\n","  tfidf_description = TfidfVectorizer()\n","  tfidf_description.fit(train_description)\n","\n","  tfidf_summary = TfidfVectorizer()\n","  tfidf_summary.fit(train_summary)\n","\n","  # tf_idf all texts\n","  all_title = tfidf_title.transform(title).toarray()\n","  all_description = tfidf_description.transform(description).toarray()\n","  all_summary = tfidf_summary.transform(summary).toarray()\n","\n","\n","  all = np.concatenate((all_description, all_title, all_summary), axis=1)\n","\n","  # Calculate distance\n","  test_data = get_data_pairs(test_pair, all)\n","  get_result([project_name, createds, test_nodes, all_nodes, test_pair, test_data])"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 227/227 [00:02<00:00, 90.36it/s]\n","100%|██████████| 619256/619256 [03:07<00:00, 3294.27it/s]\n","100%|██████████| 619256/619256 [00:25<00:00, 24409.31it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  # This is added back by InteractiveShellApp.init_path()\n","100%|██████████| 227/227 [00:00<00:00, 622.48it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","100%|██████████| 795/795 [00:16<00:00, 46.85it/s]\n","100%|██████████| 4120485/4120485 [23:06<00:00, 2970.94it/s]\n","100%|██████████| 4120485/4120485 [02:50<00:00, 24181.15it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  # This is added back by InteractiveShellApp.init_path()\n","100%|██████████| 795/795 [00:04<00:00, 181.37it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]}]},{"cell_type":"code","metadata":{"id":"cB0W9HlJJJ88","executionInfo":{"status":"ok","timestamp":1634440673072,"user_tz":-420,"elapsed":29,"user":{"displayName":"Quỳnh Mattez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh71vAUV15TmpiNe2Ds_Dbt84SL0yzA7ZZAFdXxUw=s64","userId":"09015448806943483028"}}},"source":[""],"execution_count":19,"outputs":[]}]}